{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from joblib import Parallel, delayed\n",
    "from IPython import embed as shell\n",
    "\n",
    "from tools_mcginley import utils\n",
    "import analyses_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'font.size': 12.0,\n",
       " 'axes.labelsize': 7.0,\n",
       " 'axes.titlesize': 7.0,\n",
       " 'xtick.labelsize': 6.0,\n",
       " 'ytick.labelsize': 6.0,\n",
       " 'legend.fontsize': 6.0,\n",
       " 'axes.linewidth': 0.25,\n",
       " 'grid.linewidth': 1.0,\n",
       " 'lines.linewidth': 1.5,\n",
       " 'lines.markersize': 6.0,\n",
       " 'patch.linewidth': 1.0,\n",
       " 'xtick.major.width': 0.25,\n",
       " 'ytick.major.width': 0.25,\n",
       " 'xtick.minor.width': 1.0,\n",
       " 'ytick.minor.width': 1.0,\n",
       " 'xtick.major.size': 6.0,\n",
       " 'ytick.major.size': 6.0,\n",
       " 'xtick.minor.size': 4.0,\n",
       " 'ytick.minor.size': 4.0,\n",
       " 'legend.title_fontsize': 12.0}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "sns.set(style='ticks', font='Arial', font_scale=1, rc={\n",
    "    'axes.labelsize': 7,\n",
    "    'axes.titlesize': 7,\n",
    "    'xtick.labelsize': 6,\n",
    "    'ytick.labelsize': 6,\n",
    "    'legend.fontsize': 6,\n",
    "    'axes.linewidth': 0.25,\n",
    "    'xtick.major.width': 0.25,\n",
    "    'ytick.major.width': 0.25,\n",
    "    'ytick.major.width': 0.25,\n",
    "    'ytick.major.width': 0.25,\n",
    "    'ytick.major.pad' : 2.0,\n",
    "    'ytick.minor.pad' : 2.0,\n",
    "    'xtick.major.pad' : 2.0,\n",
    "    'xtick.minor.pad' : 2.0,\n",
    "    'axes.labelpad' : 4.0,\n",
    "    'axes.titlepad' : 6.0,\n",
    "    } )\n",
    "sns.plotting_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_melt(params, model_settings, flip_b=False):\n",
    "    try:\n",
    "        params = params.loc[:,params.columns!='Unnamed: 0']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # flip b & z:\n",
    "    if flip_b:\n",
    "        params_overall = pd.DataFrame({'subj_idx': np.array(df_emp.groupby(['subj_idx']).first().index.get_level_values('subj_idx')),\n",
    "                        'c': np.array(df_emp.groupby(['subj_idx']).apply(analyses_tools.behavior, 'c'))})\n",
    "        b_columns = params.columns[[p[0]=='b' for p in params.columns]]\n",
    "        for b_column in b_columns:\n",
    "            params['{}'.format(b_column)] = params[b_column]\n",
    "            for subj in params['subj_idx'].unique():\n",
    "                if params_overall.loc[params_overall['subj_idx'] == subj, 'c'].values < 0:\n",
    "                    params.loc[params['subj_idx'] == subj, '{}'.format(b_column)] = params.loc[params['subj_idx'] == subj, '{}'.format(b_column)] * -1\n",
    "        z_columns = params.columns[[p[0]=='z' for p in params.columns]]\n",
    "        for z_column in z_columns:\n",
    "            params['{}'.format(z_column)] = params[z_column]\n",
    "            for subj in params['subj_idx'].unique():\n",
    "                if params_overall.loc[params_overall['subj_idx'] == subj, 'c'].values < 0:\n",
    "                    params.loc[params['subj_idx'] == subj, '{}'.format(z_column)] = params.loc[params['subj_idx'] == subj, '{}'.format(z_column)] * -1\n",
    "    \n",
    "    # melt:\n",
    "    params = params.melt(id_vars=['subj_idx'])\n",
    "    for i in range(params.shape[0]):\n",
    "        variable = \"\".join(itertools.takewhile(str.isalpha, params.loc[i,'variable']))\n",
    "        if variable in model_settings['depends_on']: \n",
    "            conditions = model_settings['depends_on'][variable]\n",
    "            if conditions is not None:\n",
    "                if len(conditions) == 2:\n",
    "                    params.loc[i,conditions[0]] = int(params.loc[i,'variable'][-3])\n",
    "                    params.loc[i,conditions[1]] = int(params.loc[i,'variable'][-1])\n",
    "                elif len(conditions) == 1:\n",
    "                    params.loc[i,conditions[0]] = int(params.loc[i,'variable'][-1])\n",
    "        params.loc[i,'variable'] = variable    \n",
    "    \n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all model elements:\n",
    "# -------------------\n",
    "\n",
    "project_dir = '/home/jovyan/hddm'\n",
    "# exp_names = ['yesno_audio', 'bias_manipulation_30', 'bias_manipulation_70', 'image_recognition', 'bias_manipulation',]\n",
    "# bin_measures = ['pupil_resp_1s', 'pupil_resp_1s', 'pupil_resp_1s', 'pupil_resp_1s', 'pupil_resp_1s']\n",
    "# nrs_bins = [5,3,3,2,3]\n",
    "exp_names = ['gonogo_audio_mouse', 'gonogo_audio_human', 'yesno_audio', 'bias_manipulation_30', 'bias_manipulation_70', 'image_recognition']\n",
    "bin_measures = ['pupil_stim_1s', 'pupil_stim_1s', 'pupil_resp_1s', 'pupil_resp_1s', 'pupil_resp_1s', 'pupil_resp_1s']\n",
    "nrs_bins = [5,5,5,3,3,2]\n",
    "\n",
    "n_jobs = 55\n",
    "analysis_step = 1\n",
    "# versions = [1,2,3]\n",
    "# versions = [5,6,7]\n",
    "# versions = [0,4]\n",
    "# versions = [1,2,3,5,6,7]\n",
    "# versions = [8,9,10,11]\n",
    "# versions = [8,9,10]\n",
    "# versions = [8,9,10,11]\n",
    "versions = [11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "[Parallel(n_jobs=55)]: Using backend LokyBackend with 55 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'leak'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n    for func, args, kwargs in self.items]\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/home/jovyan/hddm/accumodels/pyddm_tools.py\", line 876, in simulate_data\n    model = make_model(sample=sample, model_settings=model_settings)\n  File \"/home/jovyan/hddm/accumodels/pyddm_tools.py\", line 803, in make_model\n    leak=model_settings['leak'],\nKeyError: 'leak'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4ced71fb0823>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mdf_emp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_emp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stimulus'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stimulus'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;31m# pyddm expects -1 and 1 as stimuli identifiers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             df_sim = pd.concat(Parallel(n_jobs=n_jobs, verbose=1, backend='loky')(delayed(pyddm_tools.simulate_data)(data, params, model_settings[version], subj_idx, 100000)\n\u001b[0;32m---> 87\u001b[0;31m                                 for subj_idx, data in df_emp.groupby(['subj_idx']))).reset_index()\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0mdf_sim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fits'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'{}_{}_df_sim.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'leak'"
     ]
    }
   ],
   "source": [
    "# for analyse_exp in [0,1,2,3,4,5]:\n",
    "for analyse_exp in [0,1]:\n",
    "    exp_name, bin_measure, n_bins = exp_names[analyse_exp], bin_measures[analyse_exp], nrs_bins[analyse_exp]\n",
    "\n",
    "    # load data:\n",
    "    df = pd.read_csv(os.path.join(project_dir, 'data', 'ddm', '{}.csv'.format(exp_name)))\n",
    "\n",
    "    # compute T_dur:\n",
    "    T_dur = df['rt'].max()+1\n",
    "\n",
    "    # set options:\n",
    "    model_settings = [\n",
    "        # pyddm:\n",
    "        {'fit': 'pyddm', 'depends_on': {'a':['bin'], 'u':None,    'v':['bin'], 't':['bin'], 'z':['bin'], 'b':['bin']}, 'start_bias': True,  'drift_bias': True,  'urgency':False, 'T_dur':T_dur}, #0\n",
    "        {'fit': 'pyddm', 'depends_on': {'a':None,    'u':None,    'v':None,    't':None,    'z':['bin'], 'b':None   }, 'start_bias': True,  'drift_bias': True,  'urgency':False, 'T_dur':T_dur}, #1\n",
    "        {'fit': 'pyddm', 'depends_on': {'a':None,    'u':None,    'v':None,    't':None,    'z':None,    'b':['bin']}, 'start_bias': True,  'drift_bias': True,  'urgency':False, 'T_dur':T_dur}, #2\n",
    "        {'fit': 'pyddm', 'depends_on': {'a':None,    'u':['bin'], 'v':None,    't':None,    'z':None,    'b':None   }, 'start_bias': True,  'drift_bias': False, 'urgency':True,  'T_dur':T_dur}, #3\n",
    "        {'fit': 'pyddm', 'depends_on': {'a':['bin'], 'u':None,    'v':['bin'], 't':['bin'], 'z':['bin'], 'b':['bin']}, 'start_bias': True,  'drift_bias': True,  'urgency':True,  'T_dur':T_dur}, #4\n",
    "        {'fit': 'pyddm', 'depends_on': {'a':None,    'u':None,    'v':None,    't':None,    'z':['bin'], 'b':None   }, 'start_bias': True,  'drift_bias': False, 'urgency':True,  'T_dur':T_dur}, #5\n",
    "        {'fit': 'pyddm', 'depends_on': {'a':None,    'u':None,    'v':None,    't':None,    'z':None,    'b':['bin']}, 'start_bias': False, 'drift_bias': True,  'urgency':True,  'T_dur':T_dur}, #6\n",
    "        {'fit': 'pyddm', 'depends_on': {'a':None,    'u':['bin'], 'v':None,    't':None,    'z':None,    'b':None   }, 'start_bias': True,  'drift_bias': False, 'urgency':True,  'T_dur':T_dur}, #7\n",
    "        # hddm:\n",
    "        {'fit': 'hddm',  'depends_on':{'a':None, 'u':None, 'v':None, 't':None, 'z':None, 'b':None},                    'start_bias': True,  'drift_bias': True,  'urgency':False, 'T_dur':T_dur}, #8\n",
    "        {'fit': 'hddm',  'depends_on': {'a':['bin'], 'u':None,    'v':['bin'], 't':['bin'], 'z':['bin']},              'start_bias': True,  'drift_bias': True,  'urgency':False, 'T_dur':T_dur}, #9\n",
    "        {'fit': 'hddm',  'depends_on': {'a':['bin'], 'u':None,    'v':['bin'], 't':['bin'], 'b':['bin']},              'start_bias': True,  'drift_bias': True,  'urgency':False, 'T_dur':T_dur}, #10\n",
    "        {'fit': 'hddm',  'depends_on': {'a':['bin'], 'u':None,    'v':['bin'], 't':['bin'], 'z':['bin'], 'b':['bin']}, 'start_bias': True,  'drift_bias': True,  'urgency':False, 'T_dur':T_dur}, #11\n",
    "        ]\n",
    "    if 'gonogo' in exp_name:\n",
    "        model_settings[-4] = {'fit': 'hddm_q', 'depends_on':{'a':None, 'u':None, 'v':None, 't':None, 'z':None, 'b':None},                               'start_bias': True,  'drift_bias': True,  'urgency':False, 'T_dur':T_dur}        #8\n",
    "        model_settings[-3] = {'fit': 'hddm_q', 'depends_on':{'a':['bin'], 'u':None, 'v':['bin'], 't':['bin'], 'z':['bin'], 'b':None},                   'start_bias': True,  'drift_bias': True,  'urgency':False, 'T_dur':T_dur}        #9\n",
    "        model_settings[-2] = {'fit': 'hddm_q', 'depends_on':{'a':['bin'], 'u':None, 'v':['bin'], 't':['bin'], 'z': None,   'b':['bin']},                'start_bias': True,  'drift_bias': True,  'urgency':False, 'T_dur':T_dur}        #10\n",
    "        model_settings[-1] = {'fit': 'hddm_q', 'depends_on':{'a':['bin'], 'u':None, 'v':['bin', 'level'], 't':['bin', 'level'], 'z':None, 'b':['bin', 'level']}, 'start_bias': True, 'drift_bias': True, 'urgency':False, 'T_dur':T_dur} #11 \n",
    "    \n",
    "    for version in versions:\n",
    "\n",
    "        # cut dataframe:\n",
    "        if 'gonogo' in exp_name:\n",
    "            df_emp = df.loc[:,['subj_idx', 'response', 'rt', 'stimulus', 'correct', 'level', bin_measure]]\n",
    "            if version == 11:\n",
    "                df_emp = analyses_tools.prepare_df(df_emp)\n",
    "                df_emp['bin'] = df_emp.groupby(['subj_idx', 'level', 'stimulus'])[bin_measure].apply(pd.qcut, q=n_bins, labels=False)\n",
    "            else:\n",
    "                df_emp['level'] = 1\n",
    "                df_emp['bin'] = df_emp.groupby(['subj_idx', 'stimulus'])[bin_measure].apply(pd.qcut, q=n_bins, labels=False)\n",
    "        elif exp_name == 'image_recognition':        \n",
    "            df_emp = df.loc[:,['subj_idx', 'response', 'rt', 'stimulus', 'correct', 'emotional', bin_measure]]\n",
    "            df_emp['bin'] = df_emp.groupby(['subj_idx', 'emotional'])[bin_measure].apply(pd.qcut, q=n_bins, labels=False)\n",
    "        else:\n",
    "            df_emp = df.loc[:,['subj_idx', 'response', 'rt', 'stimulus', 'correct', bin_measure]]\n",
    "            df_emp['bin'] = df_emp.groupby(['subj_idx'])[bin_measure].apply(pd.qcut, q=n_bins, labels=False)\n",
    "\n",
    "        # fit model:\n",
    "        if analysis_step == 0:\n",
    "            \n",
    "            if model_settings[version]['fit'] == 'pyddm':\n",
    "                from accumodels import pyddm_tools\n",
    "                df_emp.loc[df_emp['stimulus']==0, 'stimulus'] = -1 # pyddm expects -1 and 1 as stimuli identifiers\n",
    "                res = Parallel(n_jobs=n_jobs, verbose=1, backend='loky')(delayed(pyddm_tools.fit_model)\n",
    "                                (data, model_settings[version], subj_idx) for subj_idx, data in df_emp.groupby(['subj_idx']))\n",
    "                params = pd.concat(res).reset_index(drop=True)\n",
    "            elif model_settings[version]['fit'] == 'hddm':\n",
    "                from accumodels import hddm_tools\n",
    "                params = hddm_tools.fit_ddm(df_emp, model_settings[version], model_dir=os.path.join(project_dir, 'fits'), \n",
    "                                                        model_name='{}_{}'.format(exp_name, version), \n",
    "                                                        samples=12500, burn=2500, thin=2, model_id=0)\n",
    "                                                        # samples=100, burn=10, thin=2, model_id=0)\n",
    "            if model_settings[version]['fit'] == 'hddm_q':\n",
    "                from accumodels import hddm_tools\n",
    "                res = Parallel(n_jobs=n_jobs, verbose=1, backend='loky')(delayed(hddm_tools.fit_ddm)\n",
    "                                (data, model_settings[version], os.path.join(project_dir, 'fits'), \n",
    "                                '{}_{}'.format(exp_name, version), subj_idx) for subj_idx, data in df_emp.groupby(['subj_idx']))\n",
    "                params = pd.concat(res).reset_index(drop=True)\n",
    "                print(params['bic'].mean())\n",
    "                # shell()\n",
    "\n",
    "            params.to_csv(os.path.join(project_dir, 'fits', '{}_{}.csv'.format(exp_name, version)))\n",
    "\n",
    "        elif analysis_step == 1:\n",
    "            \n",
    "            from accumodels import pyddm_tools, plot_tools\n",
    "\n",
    "            # simulate data:\n",
    "            params = pd.read_csv(os.path.join(project_dir, 'fits', '{}_{}.csv'.format(exp_name, version)))\n",
    "            \n",
    "            df_emp.loc[df_emp['stimulus']==0, 'stimulus'] = -1 # pyddm expects -1 and 1 as stimuli identifiers\n",
    "            df_sim = pd.concat(Parallel(n_jobs=n_jobs, verbose=1, backend='loky')(delayed(pyddm_tools.simulate_data)(data, params, model_settings[version], subj_idx, 100000)\n",
    "                                for subj_idx, data in df_emp.groupby(['subj_idx']))).reset_index()\n",
    "            df_sim.to_csv(os.path.join(project_dir, 'fits', '{}_{}_df_sim.csv'.format(exp_name, version)))\n",
    "            \n",
    "            # model fit:\n",
    "            if not 'bin' in df_sim.columns:\n",
    "                df_emp['bin'] = 1\n",
    "                df_sim['bin'] = 1\n",
    "            for b, d in df_emp.groupby(['bin']):\n",
    "                fig = plot_tools.summary_plot_group(df_emp.loc[df_emp['bin']==b,:], df_sim.loc[df_sim['bin']==b,:])\n",
    "                fig.savefig(os.path.join(project_dir, 'figs', 'ddm', '{}_{}_model_fit_{}.pdf'.format(exp_name, version, b)))\n",
    "\n",
    "    # analyses:\n",
    "    if analysis_step == 2:\n",
    "        \n",
    "        bics = []\n",
    "        resids = []\n",
    "        sdt_emps = []\n",
    "        sdt_sims = []\n",
    "        df_sims = []\n",
    "        for version in versions:\n",
    "            \n",
    "            # load:\n",
    "            params = pd.read_csv(os.path.join(project_dir, 'fits', '{}_{}.csv'.format(exp_name, version)))\n",
    "            params.loc[:, [p[0]=='a' for p in params.columns]] = params.loc[:, [p[0]=='a' for p in params.columns]] * 2 \n",
    "            if 'recognition' in exp_name:\n",
    "                params = params_melt(params, model_settings[version], flip_b=True)\n",
    "            else:\n",
    "                params = params_melt(params, model_settings[version])\n",
    "            df_sim = pd.read_csv(os.path.join(project_dir, 'fits', '{}_{}_df_sim.csv'.format(exp_name, version)))\n",
    "            df_sim.loc[df_sim['stimulus']==-1, 'stimulus'] = 0 # we now expects 0 and 1 as stimuli identifiers\n",
    "            df_sims.append(df_sim)\n",
    "\n",
    "            # empirical and simulated SDT:\n",
    "            if 'gonogo' in exp_name:\n",
    "                sdt_emp_ = analyses_tools.compute_behavior(df=df_emp, groupby=['subj_idx', 'level', 'bin'])\n",
    "                sdt_sim_ = analyses_tools.compute_behavior(df=df_sim, groupby=['subj_idx', 'level', 'bin'])\n",
    "                sdt_sim = sdt_sim_.melt(id_vars=['subj_idx', 'level', 'bin'])\n",
    "                sdt_emp = sdt_emp_.melt(id_vars=['subj_idx', 'level', 'bin'])\n",
    "\n",
    "                # collapsed across volume, including composite bias:\n",
    "                sdt_emp_bin = sdt_emp_.groupby(['subj_idx', 'bin']).mean().reset_index().drop('level', axis=1)\n",
    "                sdt_sim_bin = sdt_sim_.groupby(['subj_idx', 'bin']).mean().reset_index().drop('level', axis=1)\n",
    "                sdt_emp_bin['c2'] = np.array(df_emp.groupby(['subj_idx', 'bin']).apply(analyses_tools.composite_bias))\n",
    "                sdt_sim_bin['c2'] = np.array(df_sim.groupby(['subj_idx', 'bin']).apply(analyses_tools.composite_bias))\n",
    "                sdt_emp_bin = sdt_emp_bin.melt(id_vars=['subj_idx', 'bin'])\n",
    "                sdt_sim_bin = sdt_sim_bin.melt(id_vars=['subj_idx', 'bin'])\n",
    "\n",
    "                # collapsed across pupil bin:\n",
    "                sdt_emp_level = sdt_emp.groupby(['subj_idx', 'variable', 'level']).mean().reset_index().drop('bin', axis=1)\n",
    "                sdt_sim_level = sdt_sim.groupby(['subj_idx', 'variable', 'level']).mean().reset_index().drop('bin', axis=1)\n",
    "                \n",
    "            else:\n",
    "                sdt_emp = analyses_tools.compute_behavior(df=df_emp, groupby=['subj_idx', 'bin']).melt(id_vars=['subj_idx', 'bin'])\n",
    "                sdt_sim = analyses_tools.compute_behavior(df=df_sim, groupby=['subj_idx', 'bin']).melt(id_vars=['subj_idx', 'bin'])\n",
    "            sdt_emps.append(sdt_emp)\n",
    "            sdt_sims.append(sdt_sim)\n",
    "\n",
    "            if not 'gonogo' in exp_name:\n",
    "                if exp_name == 'image_recognition':\n",
    "                    y = np.array(sdt_emp.loc[(sdt_emp['variable']=='cf')&(sdt_emp['bin']==max(sdt_emp['bin'])), 'value']) - np.array(sdt_emp.loc[(sdt_emp['variable']=='cf')&(sdt_emp['bin']==min(sdt_emp['bin'])), 'value'])\n",
    "                else:\n",
    "                    y = np.array(sdt_emp.loc[(sdt_emp['variable']=='c')&(sdt_emp['bin']==max(sdt_emp['bin'])), 'value']) - np.array(sdt_emp.loc[(sdt_emp['variable']=='c')&(sdt_emp['bin']==min(sdt_emp['bin'])), 'value'])\n",
    "                X = np.vstack(( np.array(params.loc[(params['variable']=='z')&(params['bin']==max(params['bin'])), 'value']) - np.array(params.loc[(params['variable']=='z')&(params['bin']==min(params['bin'])), 'value']),\n",
    "                                np.array(params.loc[(params['variable']=='b')&(params['bin']==max(params['bin'])), 'value']) - np.array(params.loc[(params['variable']=='b')&(params['bin']==min(params['bin'])), 'value'])))\n",
    "                X = sm.add_constant(X.T)\n",
    "                est = sm.OLS(y, X).fit()\n",
    "                print()\n",
    "                print()\n",
    "                print(est.summary())\n",
    "                r1,p1 = sp.stats.pearsonr(y, X[:,1])\n",
    "                r2,p2 = sp.stats.pearsonr(y, X[:,2])\n",
    "\n",
    "                fig = plt.figure(figsize=(1.75,1.6))\n",
    "                ax = fig.add_subplot(111)\n",
    "                sns.regplot(x=y, y=X[:,1], color='green', scatter_kws={'s':4}, ax=ax)\n",
    "                plt.xlabel('∆ criterion (s.d.)')\n",
    "                plt.ylabel('∆ starting point')\n",
    "                ax = ax.twinx()\n",
    "                sns.regplot(x=y, y=X[:,2], scatter_kws={'s':4}, ax=ax)\n",
    "                plt.ylabel('∆ drift bias')\n",
    "                plt.title('r={}, p={}\\nr={}, p={}\\n'.format(round(r1,3), round(p1,3), round(r2,3), round(p2,3)))\n",
    "                # sns.despine(offset=2, trim=True)\n",
    "                plt.tight_layout()\n",
    "                fig.savefig(os.path.join(project_dir, 'figs', 'ddm', '{}_{}_correlations.pdf'.format(exp_name, version)))\n",
    "            \n",
    "            # DDM bars:\n",
    "            if 'gonogo' in exp_name:\n",
    "                params_bin = params.groupby(['subj_idx', 'variable', 'bin']).mean().reset_index().drop('level', axis=1)\n",
    "                params_level = params.groupby(['subj_idx', 'variable', 'level']).mean().reset_index().drop('bin', axis=1)\n",
    "                fig = analyses_tools.mixed_linear_modeling(params_bin, x='bin')\n",
    "                fig.savefig(os.path.join(project_dir, 'figs', 'ddm', '{}_{}_bars_bin.pdf'.format(exp_name, version)))\n",
    "                fig = analyses_tools.mixed_linear_modeling(params_level, x='level')\n",
    "                fig.savefig(os.path.join(project_dir, 'figs', 'ddm', '{}_{}_bars_level.pdf'.format(exp_name, version)))\n",
    "                fig = analyses_tools.mixed_linear_modeling(params.loc[~pd.isnull(params['bin'])&~pd.isnull(params['level']),:], x='bin')\n",
    "                fig.savefig(os.path.join(project_dir, 'figs', 'ddm', '{}_{}_bars1.pdf'.format(exp_name, version)))\n",
    "                \n",
    "            else:\n",
    "                fig = analyses_tools.mixed_linear_modeling(params.loc[~pd.isnull(params['bin']),:], x='bin')\n",
    "                fig.savefig(os.path.join(project_dir, 'figs', 'ddm', '{}_{}_bars.pdf'.format(exp_name, version)))\n",
    "\n",
    "            # SDT bars:\n",
    "            fig = analyses_tools.mixed_linear_modeling(sdt_emp, x='bin', df_sims=[sdt_sim], colors=['blue'])\n",
    "            fig.savefig(os.path.join(project_dir, 'figs', '{}_{}_sdt_bars.pdf'.format(exp_name, version)))\n",
    "\n",
    "            if 'gonogo' in exp_name:\n",
    "\n",
    "                fig = analyses_tools.mixed_linear_modeling(sdt_emp_bin, x='bin', df_sims=[sdt_sim_bin], colors=['blue'])\n",
    "                fig.savefig(os.path.join(project_dir, 'figs', '{}_{}_sdt_bars_bin.pdf'.format(exp_name, version)))\n",
    "\n",
    "                fig = analyses_tools.mixed_linear_modeling(sdt_emp_level, x='level', df_sims=[sdt_sim_level], colors=['blue'])\n",
    "                fig.savefig(os.path.join(project_dir, 'figs', '{}_{}_sdt_bars_level.pdf'.format(exp_name, version)))\n",
    "                        \n",
    "            # resid:\n",
    "            resid = pd.DataFrame(sdt_emp.loc[sdt_emp['variable']=='c', ['subj_idx', 'bin', 'value']]).reset_index(drop=True)\n",
    "            resid['value'] = (resid['value'] - np.array(sdt_sim.loc[sdt_emp['variable']=='c', 'value']))**2\n",
    "            resid['model'] = version\n",
    "            resids.append(resid)\n",
    "\n",
    "            # bics:\n",
    "            bic = pd.DataFrame(params.loc[params['variable']=='bic', ['subj_idx', 'value']]).reset_index(drop=True)\n",
    "            bic['model'] = version\n",
    "            bics.append(bic)\n",
    "\n",
    "        if (version == 3) | (version == 7):\n",
    "            \n",
    "            shell()\n",
    "\n",
    "            df_emp_ = df_emp.copy()\n",
    "            if exp_name == 'image_recognition':\n",
    "                sdt_emp_ = analyses_tools.compute_behavior(df=df_emp_, groupby=['subj_idx'])\n",
    "                subjects = sdt_emp_.loc[sdt_emp_['c']<0,'subj_idx']\n",
    "                df_emp_.loc[df_emp_['subj_idx'].isin(subjects), 'response'] = (~df_emp_.loc[df_emp_['subj_idx'].isin(subjects), 'response'].astype(bool)).astype(int)\n",
    "            fig = analyses_tools.conditional_response_plot(df=df_emp_, quantiles=[0,0.1,0.3,0.5,0.7,0.9,1], y='response', ylim=(0.1, 0.9), df_sims=None, color=None)\n",
    "            fig.savefig(os.path.join(project_dir, 'figs', 'ddm', '{}_{}_crf.pdf'.format(exp_name, version)))\n",
    "            fig = analyses_tools.conditional_response_plot(df=df_emp_, quantiles=[0,0.1,0.3,0.5,0.7,0.9,1], y='correct', df_sims=None, color=None)\n",
    "            fig.savefig(os.path.join(project_dir, 'figs', 'ddm', '{}_{}_caf.pdf'.format(exp_name, version)))\n",
    "\n",
    "            # SDT analysis:\n",
    "            colors = sns.color_palette(n_colors=3)\n",
    "            colors = [colors[2], colors[0], colors[1]]\n",
    "            # if exp_name == 'bias_manipulation':\n",
    "            #     for (c), d in df_emp.groupby(['cons']):\n",
    "            #         sdt_sims_ = []\n",
    "            #         for sdt_sim in sdt_sims:\n",
    "            #             sdt_sims_.append(sdt_sim.loc[(sdt_sim['cons']==c),:])\n",
    "            #         fig = analyses_tools.mixed_linear_modeling(sdt_emp.loc[(sdt_emp['cons']==c),:], x='bin', df_sims=sdt_sims_, colors=colors)\n",
    "            #         fig.savefig(os.path.join(project_dir, 'figs', 'ddm', '{}_{}_sdt_bars_{}.pdf'.format(exp_name, version, c)))\n",
    "            # else:\n",
    "            fig = analyses_tools.mixed_linear_modeling(sdt_emp, x='bin', df_sims=sdt_sims, colors=colors)\n",
    "            fig.savefig(os.path.join(project_dir, 'figs', 'ddm', '{}_{}_sdt_bars.pdf'.format(exp_name, version)))\n",
    "\n",
    "            # BICs & residuals:\n",
    "            bics = pd.concat(bics)\n",
    "            resids = pd.concat(resids)\n",
    "            # resids = resids.groupby(['subj_idx', 'model']).mean().reset_index()\n",
    "            print()\n",
    "            print(exp_name)\n",
    "            print(bics.groupby('model').mean())        \n",
    "            print(resids.groupby('model').mean())\n",
    "\n",
    "            # subtract bics:\n",
    "            subtract = np.array(bics.loc[bics['model']==bics['model'].min(), 'value'])\n",
    "            for m in bics['model'].unique():\n",
    "                bics.loc[bics['model']==m, 'value'] = np.array(bics.loc[bics['model']==m, 'value']) - subtract\n",
    "            \n",
    "            # # subtract resids:\n",
    "            # subtract = np.array(resids.loc[resids['model']==resids['model'].min(), 'value'])\n",
    "            # for m in resids['model'].unique():\n",
    "            #     resids.loc[resids['model']==m, 'value'] = np.array(resids.loc[resids['model']==m, 'value']) - subtract\n",
    "            \n",
    "            # # resids only in lowest and highest pupil bin:\n",
    "            # resids = resids.loc[(resids['bin']==min(resids['bin']))|(resids['bin']==max(resids['bin'])),:]\n",
    "\n",
    "            for data, title in zip([bics, resids], ['bic', 'resid']):\n",
    "\n",
    "                fig = plt.figure(figsize=(1.5,1.5))\n",
    "                sns.barplot(x='model', y='value', units='subj_idx', palette=colors, ci=66, data=data)\n",
    "                # sns.stripplot(x='model', y='value', color='grey', size=2, data=data)\n",
    "                if not title == 'bic':\n",
    "                    for i, m in enumerate(versions):\n",
    "\n",
    "                        if not i == 1:\n",
    "                            t,p = sp.stats.ttest_rel(resids.loc[resids['model']==m,'value'], resids.loc[resids['model']==versions[1],'value'])\n",
    "                            plt.text(i, plt.gca().get_ylim()[1]-((plt.gca().get_ylim()[1]-plt.gca().get_ylim()[0])/10), 'p={}'.format(round(p,3)), size=5, rotation=45)\n",
    "\n",
    "                plt.xticks([0,1,2], ['z', 'dc', 'u'])\n",
    "                plt.ylabel(title)\n",
    "                sns.despine(offset=2, trim=True)\n",
    "                plt.tight_layout()\n",
    "                fig.savefig(os.path.join(project_dir, 'figs', 'ddm', '{}_{}_{}.pdf'.format(exp_name, version, title)))\n",
    "\n",
    "                fig = plt.figure(figsize=(1.5,1.5))\n",
    "                if title == 'bic':\n",
    "                    sns.barplot(x='model', y='value', units='subj_idx', ci=66, errwidth=1, palette=colors, data=data)\n",
    "                    plt.xticks([0,1,2], ['z', 'dc', 'u'])\n",
    "                if title == 'resid':\n",
    "                    sns.barplot(x='bin', y='value', hue='model', units='subj_idx', ci=66, errwidth=1, palette=colors, data=data)\n",
    "                    aovrm = AnovaRM(data, 'value', 'subj_idx', within=['model','bin'], aggregate_func='mean')\n",
    "                    res = aovrm.fit()\n",
    "                    print(res)\n",
    "                    plt.title('p = {}'.format(round(res.anova_table.iloc[0]['Pr > F'],3)))\n",
    "                    # plt.xticks([0,1,2], ['z', 'dc', 'u'])\n",
    "                plt.ylabel(title)\n",
    "                try:\n",
    "                    plt.gca().get_legend().remove()\n",
    "                except:\n",
    "                    pass\n",
    "                sns.despine(offset=2, trim=True)\n",
    "\n",
    "                plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
